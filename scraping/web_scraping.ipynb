{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    "    <font color=\"#088A68\">\n",
    "        Author: lprtk\n",
    "    </font>\n",
    "</strong>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<Center>\n",
    "    <h1 style=\"font-family: Arial\">\n",
    "        <font color=\"#084B8A\">\n",
    "            NLP: sentiment analysis, topic modeling & sentiment prediction\n",
    "        </font>\n",
    "    </h1>\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#088A68\">\n",
    "            Notebook 1/5\n",
    "        </font>\n",
    "    </h3>\n",
    "</Center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h3 style=\"font-family: Arial\"><font color=\"#088A68\">Paris 1 Panth√©on-Sorbonne, M2 MoSEF 2021-2022</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#084B8A\">\n",
    "            Introduction & context\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "    This project focuses on extracting information and value from large volumes of textual data using Natural Language Processing (NLP). Why do you want to do this?\n",
    "</p>\n",
    "<ul>\n",
    "    <li><p style=\"text-align: justify\">To improve the customer experience on the website, mobile application or in the office.</p></li>\n",
    "    <li><p style=\"text-align: justify\">Assess customer satisfaction differently.</p></li>\n",
    "    <li><p style=\"text-align: justify\"></p>Evaluate the company's image.</li>\n",
    "    <li><p style=\"text-align: justify\"></p>Be more available and accessible to customers.</li>\n",
    "    <li><p style=\"text-align: justify\"></p>According to the company's activity: find new solutions to improve the banking services offered, evaluate the seller of an online sales platform or improve the product based on customer reviews.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "    Our application approach is presented in 5 main streams:\n",
    "</p>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 1:</u> Web Scraping\n",
    "        <ul>\n",
    "            <li>Collect and create the data schema.</li>\n",
    "            <li>Parsing customer reviews to enrich the database: extracting title, description, date, time, nickname and rating.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 2:</u> Sentiment Analysis and Scoring\n",
    "        <ul>\n",
    "            <li>Understand and probe the satisfaction of each customer.</li>\n",
    "            <li>Scoring the intensity and polarity of feelings from the review description.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 3:</u> Text mining and data cleaning\n",
    "        <ul>\n",
    "            <li>Text cleaning adapted to the sales domain and to the general content of reviews.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 4:</u> Topic Modeling (unsupervised learning)\n",
    "        <ul>\n",
    "            <li>To improve availability and speed up response time, reviews can be disassociated and prioritized according to the topic they address.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 5:</u> Machine Learning (supervised learning)\n",
    "        <ul>\n",
    "            <li>Without reading future reviews, design a robust model to identify the overall sentiment expressed by the customer.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#084B8A\">\n",
    "            Librairies import\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#084B8A\">\n",
    "            Web scraping\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#088A68\">\n",
    "            1) Function initialization\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Function that allows to do a web request to a web page and access to\n",
    "    his content.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Internet address: uniform resource locator (url).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        HTML body of a web page.\n",
    "\n",
    "    \"\"\"\n",
    "    content = requests.get(url, headers=headers)\n",
    "    \n",
    "    return content.text\n",
    "\n",
    "\n",
    "def html_code(url: str) -> bs4.BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Function that allows to parse the HTML body of a web page.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Internet address: uniform resource locator (url).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bs4.BeautifulSoup\n",
    "        Parsed HTML body of a web page.\n",
    "\n",
    "    \"\"\"\n",
    "    html_data = get_data(url=url)\n",
    "    soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "def cus_data(soup: str, html_tag: str, html_class: str) -> list:\n",
    "    \"\"\"\n",
    "    Function that allows to extract text from an HTML file parsed according\n",
    "    to a precise location.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    soup : bs4.BeautifulSoup\n",
    "        Parsed HTML body of a web page.\n",
    "\n",
    "    html_tag : str\n",
    "        HTML tag which indicates what to scrape.\n",
    "\n",
    "    html_class : str\n",
    "        HTML class which indicates what to scrape.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Scraped text.\n",
    "\n",
    "    \"\"\"\n",
    "    cus_list = []\n",
    "    for item in soup.find_all(html_tag, class_=html_class):\n",
    "        data_str = item.get_text()\n",
    "        cus_list.append(data_str)\n",
    "        \n",
    "    return cus_list\n",
    "\n",
    "\n",
    "def scraped_data(soup: str) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that calls a scraping function and formats the scraped data\n",
    "    into a pandas.core.frame.DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    soup : bs4.BeautifulSoup\n",
    "        Parsed HTML body of a web page.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.frame.DataFrame\n",
    "        Scraped database.\n",
    "\n",
    "    \"\"\"\n",
    "    pseudo = cus_data(\n",
    "        soup=soup,\n",
    "        html_tag=\"span\",\n",
    "        html_class=\"a-profile-name\"\n",
    "    )\n",
    "    title = cus_data(\n",
    "        soup=soup,\n",
    "        html_tag=\"a\",\n",
    "        html_class=\"a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold\"\n",
    "    )\n",
    "    review = cus_data(\n",
    "        soup=soup,\n",
    "        html_tag=\"span\",\n",
    "        html_class=\"a-size-base review-text review-text-content\"\n",
    "    )\n",
    "    rating = cus_data(\n",
    "        soup=soup,\n",
    "        html_tag=\"span\",\n",
    "        html_class=\"a-icon-alt\"\n",
    "    )\n",
    "    verified_purchase = cus_data(\n",
    "        soup=soup,\n",
    "        html_tag=\"span\",\n",
    "        html_class=\"a-size-mini a-color-state a-text-bold\"\n",
    "    )\n",
    "    date = cus_data(\n",
    "        soup=soup,\n",
    "        html_tag=\"span\",\n",
    "        html_class=\"a-size-base a-color-secondary review-date\"\n",
    "    )\n",
    "    product = cus_data(\n",
    "        soup=soup,\n",
    "        html_tag=\"div\",\n",
    "        html_class=\"a-row product-title\"\n",
    "    )\n",
    "    \n",
    "    df_data = pd.DataFrame(\n",
    "        {\n",
    "            \"Pseudo\": [\"\"],\n",
    "            \"Title\": [\"\"],\n",
    "            \"Review\": [\"\"],\n",
    "            \"Rating\": [\"\"],\n",
    "            \"Verified Purchase\": [\"\"],\n",
    "            \"Date\": [\"\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for i in range(len(title)):\n",
    "        df_scraped = pd.DataFrame(\n",
    "            {\n",
    "                \"Pseudo\": [pseudo[i]],\n",
    "                \"Title\": [title[i]],\n",
    "                \"Review\": [review[i]],\n",
    "                \"Rating\": [rating[i]],\n",
    "                \"Verified Purchase\": [verified_purchase[i]],\n",
    "                \"Date\": [date[i]]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df_data = pd.concat([df_data, df_scraped], ignore_index=True)\n",
    "\n",
    "    df_data.drop([0], axis=0, inplace=True)\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "\n",
    "def scraped_data_multipage(url: str) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that allows you to scrape across multiple review pages and\n",
    "    formats the scraped datainto a pandas.core.frame.DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Internet address: uniform resource locator (url).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.frame.DataFrame\n",
    "        Scraped database.\n",
    "\n",
    "    \"\"\"\n",
    "    page1 = \"&pageNumber=1\"\n",
    "    page2 = \"&pageNumber=2\"\n",
    "    page3 = \"&pageNumber=3\"\n",
    "    page4 = \"&pageNumber=4\"\n",
    "    page5 = \"&pageNumber=5\"\n",
    "    \n",
    "    soup = html_code(url=url+page1)\n",
    "    data_page1 = scraped_data(soup=soup)\n",
    "\n",
    "    soup = html_code(url=url+page2)\n",
    "    data_page2 = scraped_data(soup=soup)\n",
    "\n",
    "    soup = html_code(url=url+page3)\n",
    "    data_page3 = scraped_data(soup=soup)\n",
    "\n",
    "    soup = html_code(url=url+page4)\n",
    "    data_page4 = scraped_data(soup=soup)\n",
    "\n",
    "    soup = html_code(url=url+page5)\n",
    "    data_page5 = scraped_data(soup=soup)\n",
    "    \n",
    "    df_data = pd.concat(\n",
    "        [\n",
    "            data_page1,\n",
    "            data_page2,\n",
    "            data_page3,\n",
    "            data_page4,\n",
    "            data_page5\n",
    "        ]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = (\n",
    "    {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\\\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "        Chrome/90.0.4430.212 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US, en;q=0.5\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#088A68\">\n",
    "            2) Function application\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of urls to scrape\n",
    "list_urls = [\n",
    "    \"https://www.amazon.com/Razer-Blade-14-Gaming-Laptop/product-reviews/B094658SMY/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/ASUS-Processor-NumberPad-Microsoft-L210MA-DB01/product-reviews/B081V6W99V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/HP-Generation-i5-1135G7-Graphics-15-dy2024nr/product-reviews/B09FXFDGN3/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/ASUS-IPS-Type-i5-10300H-Keyboard-FX706LI-ES53/product-reviews/B08ZLC661T/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Acer-i7-1165G7-Graphics-Antimicrobial-SF514-55TA-74EC/product-reviews/B08JQKMFFB/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/HP-Portable-Micro-Edge-Anti-Glare-14-fq1025nr/product-reviews/B09G8SK2KK/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/ASUS-VivoBook-R7-3700U-Fingerprint-F512DA-NH77/product-reviews/B085344M9Q/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Dell-Inspiron-3000-Laptop-Celeron/product-reviews/B09F626YKW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Acer-AN515-55-53E5-i5-10300H-GeForce-Keyboard/product-reviews/B092YHJGMN/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Lenovo-Chromebook-11-6-Inch-Processor-82HG0006US/product-reviews/B08T6N424Z/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Apple-32GB-Space-Model-Refurbished/product-reviews/B074PWW6NS/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/ASUS-Chromebook-Spill-resistant-Transparent-CX1100CNA-AS42/product-reviews/B08XTB1NNH/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Acer-A515-56-36UT-Display-i3-1115G4-Processor/product-reviews/B08VKT45K4/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/ASUS-Processor-NumberPad-Microsoft-L210MA-DB01/product-reviews/B081V6W99V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/HP-Pavilion-Generation-i7-1165G7-15-eg0025nr/product-reviews/B09FX1YF28/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Samsung-5100mAh-Battery-SM-T290-International/product-reviews/B07XJZ7VQD/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/HP-14-Laptop-Dual-Core-Processor/product-reviews/B09VRX9YVW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/MSI-Stealth-15M-Gaming-Laptop/product-reviews/B091GGZT1S/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Apple-MacBook-Retina-MPTR2LL-Renewed/product-reviews/B07JMLMVKP/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Lenovo-Processor-Graphics-82HU00JWUS-Graphite/product-reviews/B09BG96KFJ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Samsung-Chromebook-XE500C13-K04US-Certified-Refurbished/product-reviews/B0759YSF4W/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Samsung-Chromebook-Celeron-Processor-Gigabit/product-reviews/B07XQQTVS3/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/ASUS-Chromebook-Touchscreen-Processor-C433TA-AS384T/product-reviews/B08ZLF99VD/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n",
    "    \"https://www.amazon.com/Acer-Chromebook-Celeron-Display-CB314-1H-C884/product-reviews/B0858N8CGX/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Pseudo\": [\"\"],\n",
    "        \"Title\": [\"\"],\n",
    "        \"Review\": [\"\"],\n",
    "        \"Rating\": [\"\"],\n",
    "        \"Verified Purchase\": [\"\"],\n",
    "        \"Date\": [\"\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "for i in range(len(list_urls)):\n",
    "    df_scraped = scraped_data_multipage(list_urls[i])\n",
    "    df_data = pd.concat([df_data, df_scraped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.drop([0], axis=0, inplace=True)\n",
    "df_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1136 entries, 0 to 1135\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Pseudo             1136 non-null   object\n",
      " 1   Title              1136 non-null   object\n",
      " 2   Review             1136 non-null   object\n",
      " 3   Rating             1136 non-null   object\n",
      " 4   Verified Purchase  1136 non-null   object\n",
      " 5   Date               1136 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 53.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#084B8A\">\n",
    "            Data export\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_csv(path_or_buf=\"amzn_customer_reviews.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
